"""
åˆ†æ bench_results/reme_simple/tmp ç›®å½•ä¸‹çš„è¯„ä¼°ç»“æœ

ç»Ÿè®¡æ‰€æœ‰ç”¨æˆ·sessionä¸­çš„result_typeåˆ†å¸ƒï¼Œå¹¶è¾“å‡ºéCorrectç»“æœçš„è¯¦ç»†ä½ç½®ä¿¡æ¯ã€‚
"""

import json
from collections import Counter
from pathlib import Path
from typing import Dict, List, Tuple


def analyze_results(tmp_dir: str = "bench_results/reme_simple/tmp"):
    """
    åˆ†æè¯„ä¼°ç»“æœç›®å½•ã€‚
    
    Args:
        tmp_dir: ä¸´æ—¶ç»“æœç›®å½•è·¯å¾„
    """
    tmp_path = Path(tmp_dir)
    
    if not tmp_path.exists():
        print(f"âŒ ç›®å½•ä¸å­˜åœ¨: {tmp_dir}")
        return
    
    # ç»Ÿè®¡æ•°æ®
    result_counter = Counter()
    non_correct_results = []  # å­˜å‚¨éCorrectç»“æœçš„è¯¦ç»†ä¿¡æ¯
    
    # éå†æ‰€æœ‰ç”¨æˆ·ç›®å½•
    user_dirs = sorted([d for d in tmp_path.iterdir() if d.is_dir()])
    
    if not user_dirs:
        print(f"âŒ {tmp_dir} ä¸‹æ²¡æœ‰ç”¨æˆ·ç›®å½•")
        return
    
    print(f"ğŸ“ æ‰¾åˆ° {len(user_dirs)} ä¸ªç”¨æˆ·ç›®å½•\n")
    print("=" * 80)
    print("å¼€å§‹åˆ†æ...")
    print("=" * 80 + "\n")
    
    total_sessions = 0
    total_questions = 0
    
    # éå†æ¯ä¸ªç”¨æˆ·ç›®å½•
    for user_dir in user_dirs:
        user_name = user_dir.name
        
        # è·å–è¯¥ç”¨æˆ·çš„æ‰€æœ‰sessionæ–‡ä»¶
        session_files = sorted([
            f for f in user_dir.iterdir() 
            if f.name.startswith("session_") and f.suffix == ".json"
        ])
        
        if not session_files:
            continue
        
        # éå†æ¯ä¸ªsession
        for session_file in session_files:
            try:
                with open(session_file, "r", encoding="utf-8") as f:
                    session_data = json.load(f)
                
                session_id = session_data.get("session_id", -1)
                total_sessions += 1
                
                # è·³è¿‡ç”Ÿæˆçš„QA session
                if session_data.get("is_generated_qa_session", False):
                    continue
                
                # è·å–è¯„ä¼°ç»“æœ
                eval_results = session_data.get("evaluation_results", {})
                qa_records = eval_results.get("question_answering_records", [])
                
                # åˆ†ææ¯ä¸ªé—®é¢˜çš„ç»“æœ
                for qa_idx, qa_record in enumerate(qa_records):
                    result_type = qa_record.get("result_type", "Unknown")
                    
                    # ç»Ÿè®¡result_type
                    result_counter[result_type] += 1
                    total_questions += 1
                    
                    # å¦‚æœä¸æ˜¯Correctï¼Œè®°å½•è¯¦ç»†ä¿¡æ¯
                    if result_type != "Correct":
                        non_correct_results.append({
                            "user_name": user_name,
                            "session_id": session_id,
                            "question_id": qa_idx,
                            "result_type": result_type,
                            "question": qa_record.get("question", ""),
                            "answer": qa_record.get("answer", ""),
                            "system_response": qa_record.get("system_response", "")
                        })
                
            except Exception as e:
                print(f"âš ï¸  è¯»å–æ–‡ä»¶å¤±è´¥: {session_file}, é”™è¯¯: {e}")
                continue
    
    # è¾“å‡ºç»Ÿè®¡ç»“æœ
    print("\n" + "=" * 80)
    print("ç»Ÿè®¡ç»“æœ")
    print("=" * 80 + "\n")
    
    print(f"ğŸ“Š æ€»ç”¨æˆ·æ•°: {len(user_dirs)}")
    print(f"ğŸ“Š æ€»Sessionæ•°: {total_sessions}")
    print(f"ğŸ“Š æ€»é—®é¢˜æ•°: {total_questions}\n")
    
    if total_questions == 0:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°ä»»ä½•é—®é¢˜æ•°æ®")
        return
    
    # è¾“å‡ºresult_typeåˆ†å¸ƒ
    print("=" * 80)
    print("Result Type åˆ†å¸ƒ")
    print("=" * 80 + "\n")
    
    # æŒ‰æ•°é‡é™åºæ’åˆ—
    sorted_results = sorted(result_counter.items(), key=lambda x: x[1], reverse=True)
    
    for result_type, count in sorted_results:
        ratio = count / total_questions * 100
        print(f"  {result_type:20s}: {count:5d} ({ratio:6.2f}%)")
    
    # è¾“å‡ºéCorrectç»“æœçš„è¯¦ç»†ä¿¡æ¯
    if non_correct_results:
        print("\n" + "=" * 80)
        print(f"é Correct ç»“æœè¯¦æƒ… (å…± {len(non_correct_results)} æ¡)")
        print("=" * 80 + "\n")
        
        for idx, result in enumerate(non_correct_results, 1):
            print(f"[{idx}] {result['result_type']}")
            print(f"    ç”¨æˆ·: {result['user_name']}")
            print(f"    ä½ç½®: Session {result['session_id']}, Question {result['question_id']}")
            print(f"    é—®é¢˜: {result['question']}")
            print(f"    æ­£ç¡®ç­”æ¡ˆ: {result['answer']}")
            print(f"    ç³»ç»Ÿå›ç­”: {result['system_response'][:200]}{'...' if len(result['system_response']) > 200 else ''}")
            print()
    
    else:
        print("\nğŸ‰ æ‰€æœ‰é—®é¢˜éƒ½æ˜¯ Correct!")
    
    # ä¿å­˜è¯¦ç»†æŠ¥å‘Šåˆ°æ–‡ä»¶
    report_file = Path(tmp_dir).parent / "analysis_report.json"
    report_data = {
        "summary": {
            "total_users": len(user_dirs),
            "total_sessions": total_sessions,
            "total_questions": total_questions,
            "result_type_distribution": dict(result_counter),
            "result_type_ratio": {
                result_type: count / total_questions 
                for result_type, count in result_counter.items()
            }
        },
        "non_correct_results": non_correct_results
    }
    
    with open(report_file, "w", encoding="utf-8") as f:
        json.dump(report_data, f, ensure_ascii=False, indent=2)
    
    print("=" * 80)
    print(f"ğŸ“„ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")
    print("=" * 80)


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(
        description="åˆ†æ ReMe è¯„ä¼°ç»“æœä¸­çš„ result_type åˆ†å¸ƒ"
    )
    parser.add_argument(
        "--tmp_dir",
        type=str,
        default="bench_results/reme_simple/tmp",
        help="ä¸´æ—¶ç»“æœç›®å½•è·¯å¾„ (é»˜è®¤: bench_results/reme_simple/tmp)"
    )
    
    args = parser.parse_args()
    analyze_results(args.tmp_dir)
