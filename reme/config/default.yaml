backend: http
thread_pool_max_workers: 64

mcp:
  transport: sse
  host: "0.0.0.0"
  port: 8001

http:
  host: "0.0.0.0"
  port: 8002
  timeout_keep_alive: 600
  limit_concurrency: 64

flows:
  test:
    flow_content: TestOp()
    description: "test"

llms:
  default:
    backend: openai
    model_name: qwen3-30b-a3b-instruct-2507
#    model_name: qwen3-30b-a3b-thinking-2507
    request_interval: 1
#    temperature: 0.0001

  qwen3_max_instruct:
    backend: openai
    model_name: qwen3-max
    request_interval: 2

  qwen-plus-thinking:
    backend: openai
    model_name: qwen-plus
    request_interval: 1
    extra_body:
      enable_thinking: True

embedding_models:
  default:
    backend: openai
    model_name: text-embedding-v4
    dimensions: 1024

vector_stores:
  default:
    backend: chroma
#    backend: local
    embedding_model: default
    collection_name: reme

token_counters:
  default:
    backend: base

  hf:
    backend: hf
    model_name: Qwen/Qwen3-Coder-30B-A3B-Instruct
    use_mirror: true

